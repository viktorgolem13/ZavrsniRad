{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as nr\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sentinels import NOTHING\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train(df, features, nFeatures, targetedClass, classifier):\n",
    "    \n",
    "    nRows = df.shape[0]\n",
    "    \n",
    "    X = df[features].as_matrix().reshape(nRows, nFeatures)\n",
    "    \n",
    "    Y = df[targetedClass].as_matrix().ravel()\n",
    "    \n",
    "    trainedClassifier = classifier.fit(X, Y)\n",
    "    \n",
    "    return trainedClassifier\n",
    "\n",
    "def test(df, features, nFeatures, targetedClass, trainedClassifier):\n",
    "    \n",
    "    nRows = df.shape[0]\n",
    "    \n",
    "    X = df[features].as_matrix().reshape(nRows, nFeatures)\n",
    "    \n",
    "    df.predicted = trainedClassifier.predict(X)\n",
    "    \n",
    "    Y = df[targetedClass].as_matrix().ravel()\n",
    "    print('Score: ', trainedClassifier.score(X, Y))\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "def treeClassification(df, targetedClass, maxDepthParameter = None):\n",
    "    from sklearn import tree\n",
    "    \n",
    "    if maxDepthParameter == None:\n",
    "        maxDepthValues = []\n",
    "        for i in range(1, 30):\n",
    "            maxDepthValues.append(i)\n",
    "            \n",
    "        algorithmParameters = {'max_depth':maxDepthValues}\n",
    "        model = tree.DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "        grid = GridSearchCV(model, algorithmParameters)\n",
    "        grid.fit(df, df[targetedClass])\n",
    "\n",
    "        #print(grid.best_score_)\n",
    "        print('maxDepthParameter: ', grid.best_estimator_.max_depth)\n",
    "        maxDepthParameter = grid.best_estimator_.max_depth\n",
    "    \n",
    "    treeClassifier = tree.DecisionTreeClassifier(max_depth = maxDepthParameter)\n",
    "    \n",
    "    return treeClassifier\n",
    "\n",
    "\n",
    "def logisticRegression(df, targetedClass, cParameter = None):\n",
    "    from sklearn import linear_model\n",
    "    \n",
    "    if cParameter == None:\n",
    "        cValues = []\n",
    "        for i in range(1, 100):\n",
    "            cValues.append(i*0.1)\n",
    "            \n",
    "        algorithmParameters = {'C':cValues}\n",
    "        model = linear_model.LogisticRegression()\n",
    "\n",
    "\n",
    "        grid = GridSearchCV(model, algorithmParameters)\n",
    "        grid.fit(df, df[targetedClass])\n",
    "\n",
    "        #print(grid.best_score_)\n",
    "        print('cParameter: ', grid.best_estimator_.C)\n",
    "        cParameter = grid.best_estimator_.C\n",
    "        \n",
    "    logisticRegressionClassifier = linear_model.LogisticRegression(C = cParameter)\n",
    "    \n",
    "    return logisticRegressionClassifier\n",
    "\n",
    "\n",
    "def SVMClassification(df, targetedClass, cParameter = None, kernelParameter = None):\n",
    "    from sklearn import svm\n",
    "    \n",
    "    if cParameter == None and kernelParameter == None:\n",
    "        \n",
    "        cValues = []\n",
    "        for i in range(1, 10):\n",
    "            cValues.append(0.01*3**i)\n",
    "            \n",
    "        kernelValues = ['linear', 'poly', 'rbf']\n",
    "            \n",
    "        algorithmParameters = {'C':cValues, 'kernel':kernelValues}\n",
    "        model = svm.SVC()\n",
    "\n",
    "        grid = GridSearchCV(model, algorithmParameters)\n",
    "        grid.fit(df, df[targetedClass])\n",
    "\n",
    "        #print(grid.best_score_)\n",
    "        print('C: ', grid.best_estimator_.C)\n",
    "        print('Kernel: ', grid.best_estimator_.kernel)\n",
    "        cParameter = grid.best_estimator_.C\n",
    "        kernelParameter = grid.best_estimator_.kernel\n",
    "    \n",
    "    elif cParameter == None:\n",
    "        cValues = []\n",
    "        for i in range(1, 40):\n",
    "            cValues.append(0.001 * 1.5**i)\n",
    "            \n",
    "        algorithmParameters = {'C':cValues}\n",
    "        model = svm.SVC(kernel = kernelParameter)\n",
    "\n",
    "\n",
    "        grid = GridSearchCV(model, algorithmParameters)\n",
    "        grid.fit(df, df.target)\n",
    "\n",
    "        #print(grid.best_score_)\n",
    "        print('cParameter: ', grid.best_estimator_.C)\n",
    "        cParameter = grid.best_estimator_.C\n",
    "        \n",
    "    elif kernelParameter == None:\n",
    "        kernelValues = ['linear', 'poly', 'rbf']\n",
    "            \n",
    "        algorithmParameters = {'kernel':kernelValues}\n",
    "        model = svm.SVC(C = cParameter)\n",
    "\n",
    "        grid = GridSearchCV(model, algorithmParameters)\n",
    "        grid.fit(df, df[targetedClass])\n",
    "\n",
    "        #print(grid.best_score_)\n",
    "        print('kernelParameter: ', grid.best_estimator_.kernel)\n",
    "        kernelParameter = grid.best_estimator_.kernel\n",
    "    \n",
    "    SVMClassifier = svm.SVC(C = cParameter, kernel = kernelParameter)\n",
    "\n",
    "    return SVMClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def forestClassification(df, targetedClass, nEstimatorsParameter = None, maxDepthParametar = NOTHING, maxLeafNodesParameter = NOTHING, minSamplesLeafParametar  = None):\n",
    "    \n",
    "    from sklearn import ensemble\n",
    "    \n",
    "    algorithmParameters = dict()\n",
    "    \n",
    "    if maxLeafNodesParameter == NOTHING:\n",
    "        maxLeafNodesValues = []\n",
    "        for i in range(1,15):\n",
    "            maxLeafNodesValues.append(2**i)\n",
    "            \n",
    "        maxLeafNodesValues.append(None)\n",
    "            \n",
    "        algorithmParameters['max_leaf_nodes'] = maxLeafNodesValues\n",
    "        \n",
    "    if nEstimatorsParameter == None:\n",
    "        nEstimatorsValues = []\n",
    "        for i in range(1, 20):\n",
    "            nEstimatorsValues.append(2*i)\n",
    "            \n",
    "        algorithmParameters['n_estimators'] = nEstimatorsValues\n",
    "        \n",
    "    if maxDepthParametar == NOTHING:\n",
    "        maxDepthValues = []\n",
    "        for i in range(1, 20):#vratit na 30\n",
    "            maxDepthValues.append(2*i)\n",
    "            \n",
    "        algorithmParameters['max_depth'] = maxDepthValues\n",
    "        \n",
    "    if minSamplesLeafParametar == None:\n",
    "        minSamplesLeafValues = []\n",
    "        for i in range(1, 10):\n",
    "            minSamplesLeafValues.append(2*i)\n",
    "            \n",
    "        algorithmParameters['min_samples_leaf'] = minSamplesLeafValues\n",
    "        \n",
    "    if maxLeafNodesParameter == NOTHING:\n",
    "        tempMaxLeafNodesParameter = None\n",
    "    else:\n",
    "        tempMaxLeafNodesParameter = maxLeafNodesParameter\n",
    "        \n",
    "    if nEstimatorsParameter == None:\n",
    "        tempNEstimatorsParameter = 10\n",
    "    else:\n",
    "        tempNEstimatorsParameter = nEstimatorsParameter\n",
    "        \n",
    "    if maxDepthParametar == NOTHING:\n",
    "        tempMaxDepthParametar = None\n",
    "    else:\n",
    "        tempMaxDepthParametar = maxDepthParametar\n",
    "        \n",
    "    if minSamplesLeafParametar == None:\n",
    "        tempMinSamplesLeafParametar = 1\n",
    "    else:\n",
    "        tempMinSamplesLeafParametar = minSamplesLeafParametar\n",
    "        \n",
    "    \n",
    "    model = ensemble.RandomForestClassifier(max_leaf_nodes = tempMaxLeafNodesParameter, \n",
    "                                            n_estimators = tempNEstimatorsParameter, max_depth = tempMaxDepthParametar,\n",
    "                                            min_samples_leaf = tempMinSamplesLeafParametar)\n",
    "\n",
    "    grid = GridSearchCV(model, algorithmParameters)\n",
    "    grid.fit(df, df[targetedClass])\n",
    "\n",
    "    #print(grid.best_score_)\n",
    "    if nEstimatorsParameter == None:\n",
    "        print('nEstimatorsParameter: ', grid.best_estimator_.n_estimators)\n",
    "        nEstimatorsParameter = grid.best_estimator_.n_estimators\n",
    "        \n",
    "    if maxLeafNodesParameter == NOTHING:  \n",
    "        #print(grid.best_score_)\n",
    "        print('maxLeafNodesParameter: ', grid.best_estimator_.max_leaf_nodes)\n",
    "        maxLeafNodesParameter = grid.best_estimator_.max_leaf_nodes\n",
    "        \n",
    "        \n",
    "    if maxDepthParametar == NOTHING:\n",
    "        print('maxDepthParametar: ', grid.best_estimator_.max_depth)\n",
    "        maxDepthParametar = grid.best_estimator_.max_depth\n",
    "        \n",
    "    if minSamplesLeafParametar == None:   \n",
    "        #print(grid.best_score_)\n",
    "        print('minSamplesLeafParametar: ', grid.best_estimator_.min_samples_leaf)\n",
    "        minSamplesLeafParametar = grid.best_estimator_.min_samples_leaf\n",
    "    \n",
    "    forestClassifier = ensemble.RandomForestClassifier(max_leaf_nodes = maxLeafNodesParameter, n_estimators = nEstimatorsParameter,\n",
    "                                                      max_depth = maxDepthParametar, min_samples_leaf = minSamplesLeafParametar)\n",
    "    \n",
    "    return forestClassifier\n",
    "\n",
    "def intToColor(i):\n",
    "    if(i == 0):\n",
    "        return 'blue'\n",
    "    elif(i == 1):\n",
    "        return 'green'\n",
    "    elif(i == 2):\n",
    "        return 'red'\n",
    "    elif(i == 3):\n",
    "        return 'cyan'\n",
    "    elif(i == 4):\n",
    "        return 'magenta'\n",
    "    elif(i == 5):\n",
    "        return 'yellow'\n",
    "    elif(i == 6):\n",
    "        return 'black'\n",
    "    elif(i == 7):\n",
    "        return 'darkviolet'\n",
    "    elif(i == 8):\n",
    "        return 'pink'\n",
    "\n",
    "\n",
    "def plotClassification(df, targetedClass, feature, nClasses):\n",
    "\n",
    "    true = []\n",
    "    false = []\n",
    "    \n",
    "    for i in range(nClasses):\n",
    "        true.append( df[( (df.predicted == i) & (df[targetedClass] == i))] )\n",
    "        false.append( df[((df.predicted == i) & (df[targetedClass] != i))] )\n",
    "    \n",
    "    for i in range(nClasses):\n",
    "        print(true[i][feature].count() / (true[i][feature].count() + false[i][feature].count()))\n",
    "        \n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "\n",
    "    ax = fig.gca()\n",
    "    \n",
    "    for i in range(nClasses):\n",
    "        color = intToColor(i)\n",
    "        if true[i][feature].count() != 0:\n",
    "            true[i].plot(kind = 'scatter', x = 'feat_1', y = 'feat_13', ax = ax, color = color, marker = 'o', alpha = 0.2)\n",
    "        if false[i][feature].count() != 0:\n",
    "            false[i].plot(kind = 'scatter', x = 'feat_1', y = 'feat_13', ax = ax, color = color, marker = 'x', alpha = 0.2)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
      "0   1       1       0       0       0       0       0       0       0       0   \n",
      "1   2       0       0       0       0       0       0       0       1       0   \n",
      "2   3       0       0       0       0       0       0       0       1       0   \n",
      "3   4       1       0       0       1       6       1       5       0       0   \n",
      "4   5       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "    ...     feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  feat_91  \\\n",
      "0   ...           1        0        0        0        0        0        0   \n",
      "1   ...           0        0        0        0        0        0        0   \n",
      "2   ...           0        0        0        0        0        0        0   \n",
      "3   ...           0        1        2        0        0        0        0   \n",
      "4   ...           1        0        0        0        0        1        0   \n",
      "\n",
      "   feat_92  feat_93   target  \n",
      "0        0        0  Class_1  \n",
      "1        0        0  Class_1  \n",
      "2        0        0  Class_1  \n",
      "3        0        0  Class_1  \n",
      "4        0        0  Class_1  \n",
      "\n",
      "[5 rows x 95 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\viktor\\\\Downloads\\\\ottoTest\\\\train.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['target'] = df['target'].astype('category').cat.codes\n",
    "features = []\n",
    "nFeatures = 93\n",
    "for i in range(1, nFeatures + 1):\n",
    "\tparameter = 'feat_' + str(i)\n",
    "\tfeatures.append(parameter)\n",
    "\n",
    "dfTrain, dfTest = train_test_split(df, train_size = 0.2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.74920711876\n"
     ]
    }
   ],
   "source": [
    "classifier = logisticRegression(dfTrain, 'target', cParameter = 8.5)#rezultat 0.74-0.75 neovisno o C\n",
    "trainedClassifier = train(dfTrain, features, nFeatures, 'target', classifier)\n",
    "\n",
    "dfTest = test(dfTest, features, nFeatures, 'target', trainedClassifier)\n",
    "\n",
    "#plotClassification(dfTest, 'target', 'feat_1', 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.75429771933\n"
     ]
    }
   ],
   "source": [
    "classifier = SVMClassification(dfTrain, 'target', cParameter = 2.2, kernelParameter = \"rbf\") #best c for default kernel\n",
    "trainedClassifier = train(dfTrain, features, nFeatures, 'target', classifier)\n",
    "\n",
    "dfTest = test(dfTest, features, nFeatures, 'target', trainedClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.742904470436\n"
     ]
    }
   ],
   "source": [
    "classifier = SVMClassification(dfTrain, 'target', 1, \"rbf\") # default values for kernel and c\n",
    "trainedClassifier = train(dfTrain, features, nFeatures, 'target', classifier)\n",
    "\n",
    "dfTest = test(dfTest, features, nFeatures, 'target', trainedClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.752055430984\n"
     ]
    }
   ],
   "source": [
    "classifier = SVMClassification(dfTrain, 'target', cParameter = 0.0113, kernelParameter = \"linear\")#best c for linear kernel\n",
    "trainedClassifier = train(dfTrain, features, nFeatures, 'target', classifier)\n",
    "\n",
    "dfTest = test(dfTest, features, nFeatures, 'target', trainedClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.634749409127\n"
     ]
    }
   ],
   "source": [
    "classifier = treeClassification(dfTrain, 'target', maxDepthParameter = 11) \n",
    "trainedClassifier = train(dfTrain, features, nFeatures, 'target', classifier)\n",
    "\n",
    "dfTest = test(dfTest, features, nFeatures, 'target', trainedClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.741914631436\n"
     ]
    }
   ],
   "source": [
    "classifier = forestClassification(dfTrain, 'target', nEstimatorsParameter = 10, maxDepthParametar =  None, \n",
    "                                  maxLeafNodesParameter = None, minSamplesLeafParametar = 1) #default values\n",
    "\n",
    "trainedClassifier = train(dfTrain, features, nFeatures, 'target', classifier)\n",
    "\n",
    "dfTest = test(dfTest, features, nFeatures, 'target', trainedClassifier)\n",
    "\n",
    "#plotClassification(dfTest, 'target', 'feat_1', 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.744419530129\n"
     ]
    }
   ],
   "source": [
    "classifier = forestClassification(dfTrain, 'target', nEstimatorsParameter = 10,\n",
    "                                 maxLeafNodesParameter = 16384, maxDepthParametar = 26\n",
    "                                , minSamplesLeafParametar = 2) #1 default value\n",
    "\n",
    "trainedClassifier = train(dfTrain, features, nFeatures, 'target', classifier)\n",
    "\n",
    "dfTest = test(dfTest, features, nFeatures, 'target', trainedClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.765145546735\n"
     ]
    }
   ],
   "source": [
    "classifier = forestClassification(dfTrain, 'target', nEstimatorsParameter = 40, maxDepthParametar = None,\n",
    "                                 maxLeafNodesParameter = None, minSamplesLeafParametar = 2) #2 default values\n",
    "trainedClassifier = train(dfTrain, features, nFeatures, 'target', classifier)\n",
    "\n",
    "dfTest = test(dfTest, features, nFeatures, 'target', trainedClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.766781811203\n"
     ]
    }
   ],
   "source": [
    "classifier = forestClassification(dfTrain, 'target', nEstimatorsParameter = 34, maxDepthParametar =  None, \n",
    "                                  maxLeafNodesParameter = None, minSamplesLeafParametar = 1) #3 default values\n",
    "\n",
    "trainedClassifier = train(dfTrain, features, nFeatures, 'target', classifier)\n",
    "\n",
    "dfTest = test(dfTest, features, nFeatures, 'target', trainedClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.763468880674\n"
     ]
    }
   ],
   "source": [
    "classifier = forestClassification(dfTrain, 'target', nEstimatorsParameter = 40, #ideal hyperparameters\n",
    "                        maxLeafNodesParameter = None, maxDepthParametar = 38\n",
    "                        , minSamplesLeafParametar = 2)\n",
    "\n",
    "trainedClassifier = train(dfTrain, features, nFeatures, 'target', classifier)\n",
    "dfTest = test(dfTest, features, nFeatures, 'target', trainedClassifier)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
